{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country high_income  \n",
      "0          2174             0              40   United-States       <=50K  \n",
      "1             0             0              13   United-States       <=50K  \n",
      "2             0             0              40   United-States       <=50K  \n",
      "3             0             0              40   United-States       <=50K  \n",
      "4             0             0              40            Cuba       <=50K  \n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "import pandas\n",
    "\n",
    "names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\", \n",
    "         \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \n",
    "         \"hours_per_week\", \"native_country\", \"high_income\"]\n",
    "income = pandas.read_csv(\"income.csv\", header=None, names=names, index_col=False)\n",
    "print(income.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7\n",
      "1    6\n",
      "2    4\n",
      "3    4\n",
      "4    4\n",
      "Name: workclass, dtype: int8\n",
      "0     9\n",
      "1     9\n",
      "2    11\n",
      "3     1\n",
      "4     9\n",
      "Name: education, dtype: int8\n",
      "0    4\n",
      "1    2\n",
      "2    0\n",
      "3    2\n",
      "4    2\n",
      "Name: marital_status, dtype: int8\n",
      "0     1\n",
      "1     4\n",
      "2     6\n",
      "3     6\n",
      "4    10\n",
      "Name: occupation, dtype: int8\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    5\n",
      "Name: relationship, dtype: int8\n",
      "0    4\n",
      "1    4\n",
      "2    4\n",
      "3    2\n",
      "4    2\n",
      "Name: race, dtype: int8\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: sex, dtype: int8\n",
      "0    39\n",
      "1    39\n",
      "2    39\n",
      "3    39\n",
      "4     5\n",
      "Name: native_country, dtype: int8\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: high_income, dtype: int8\n"
     ]
    }
   ],
   "source": [
    "# When we construct a decision tree, we'll need to be able to deal with numbers. \n",
    "# Therefore, we will convert the categorical variables in our dataset to numeric variables.\n",
    "# We use the Categorical.from_array method from Pandas to perform the conversion to numbers.\n",
    "\n",
    "convert_list = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', \n",
    "                'race', 'sex', 'native_country', 'high_income']\n",
    "for column in convert_list:\n",
    "    col = pandas.Categorical.from_array(income[column])\n",
    "    income[column] = col.codes\n",
    "    print(income[column].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we split when we construct decision trees, we pick a random sample of features from the data. We then compute the information gain for each feature in our random sample, and pick the one with the highest information gain to split on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Gain:\n",
    "\n",
    "For a simpler explanation of information gain, we're finding the entropy of each set post-split, weighting it by the number of items in each split, then subtracting from the current entropy. If it's positive, we've lowered entropy with our split. The higher it is, the more we've lowered entropy. \n",
    "\n",
    "Since Our goal is to ensure that we can make a prediction on future data. In order to do this, all rows in each leaf must have only one value for our target column. If this doesn't happen, we won't be able to make effective predictions. And each split should be closer to the final goal.\n",
    "\n",
    "Therefore we are going to select the variable which lowers the entropy most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796383955202\n"
     ]
    }
   ],
   "source": [
    "# Let's first get more familiar with the concept of entropy and information gain.\n",
    "# We will compute the entropy of the high_income column in the income dataframe \n",
    "import math\n",
    "\n",
    "high_income = sum(income['high_income'] == 1)\n",
    "total = income.shape[0]\n",
    "high_ratio = high_income / total\n",
    "low_ratio = 1 - high_ratio\n",
    "income_entropy = - (high_ratio * math.log(high_ratio, 2) + low_ratio * math.log(low_ratio, 2))\n",
    "\n",
    "print(income_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0470286613047\n"
     ]
    }
   ],
   "source": [
    "# And we will also compute the information gain for splitting on the age column of income\n",
    "import numpy\n",
    "\n",
    "# Calculate entropy given a pandas Series, list, or numpy array.\n",
    "def calc_entropy(column):\n",
    "    \n",
    "    counts = numpy.bincount(column)\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    entropy = 0\n",
    "    for prob in probabilities:\n",
    "        if prob > 0: \n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    return -entropy\n",
    "\n",
    "median_age = numpy.median(income['age'])\n",
    "left_split = income[income['age'] <= median_age]\n",
    "right_split = income[income['age'] > median_age]\n",
    "\n",
    "left_entropy = calc_entropy(left_split['high_income'])\n",
    "right_entropy = calc_entropy(right_split['high_income'])\n",
    "total_entropy = calc_entropy(income['high_income'])\n",
    "\n",
    "age_information_gain = total_entropy - (len(left_split) / len(income) * left_entropy + \n",
    "                                        len(right_split) / len(income) * right_entropy)\n",
    "print(age_information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list called information_gains. It should contain, in order, the information gain from splitting on these columns: age, workclass, education_num, marital_status, occupation, relationship, race, sex, hours_per_week, native_country.\n",
    "\n",
    "Find the highest value in the information_gains list. Assign the name of the column with the highest information gain to highest_gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital_status\n"
     ]
    }
   ],
   "source": [
    "# Calculate information gain given a dataset, column to split on, and the target column.\n",
    "\n",
    "def calc_information_gain(data_set, split_name, target_name):\n",
    "\n",
    "    median = numpy.median(data_set[split_name])\n",
    "    left_split = data_set[data_set[split_name] <= median]\n",
    "    right_split = data_set[data_set[split_name] > median]\n",
    "    \n",
    "    left_entropy = calc_entropy(left_split[target_name])\n",
    "    right_entropy = calc_entropy(right_split[target_name])\n",
    "    total_entropy = calc_entropy(data_set[target_name])\n",
    "    \n",
    "    information_gain = total_entropy - (len(left_split) / len(data_set) * left_entropy +\n",
    "                                       len(right_split) / len(data_set) * right_entropy)\n",
    "    return information_gain\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "           \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "information_gains = []\n",
    "\n",
    "# Calculate information gain for each variable in dataset and find the variable that has the\n",
    "# largest information gain.\n",
    "for col in columns:\n",
    "    information_gains.append(calc_information_gain(income, col, 'high_income'))\n",
    "\n",
    "index = information_gains.index(max(information_gains))\n",
    "highest_gain = columns[index]\n",
    "print(highest_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital_status\n"
     ]
    }
   ],
   "source": [
    "# To wrap up, write a function that returns the name of a column to split the data on\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    # find the column in columns to split on.\n",
    "    \n",
    "    information_gains = []\n",
    "    for col in columns:\n",
    "        information_gains.append(calc_information_gain(data, col, target_name))\n",
    "    index = information_gains.index(max(information_gains))\n",
    "    return columns[index]\n",
    "\n",
    "# A list of columns to potentially split income with.\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "           \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "income_split = find_best_column(income, 'high_income', columns)\n",
    "print(income_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After knowing the basics of entropy and information gain, we'll use the ID3 Algorithm to construct full decision trees. This algorithm involves recursion. \n",
    "\n",
    "In general, recursion is the process of splitting a large problem into small chunks. Recursive functions will call themselves, then combine the results to create a final result.\n",
    "\n",
    "Building trees is a perfect case for a recursive algorithm -- at each node, we'll call a recursive function, which will split the data into two branches. Each branch will lead to a node, and the function will call itself to build out the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1] [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# To build up to making the full id3 function, first build a simpler algorithm that we can \n",
    "# extend. we'll just count up how many leaves end up with the label 1 (>50k), and how many \n",
    "# end up with the label 0 (<= 50k).\n",
    "\n",
    "label_1s = []\n",
    "label_0s = []\n",
    "def id3(data_set, target, columns):\n",
    "    unique_targets = pandas.unique(data_set[target])\n",
    "    \n",
    "    if len(unique_targets) == 1:\n",
    "        if (unique_targets[0] == 1):\n",
    "            label_1s.append(1)\n",
    "        elif(unique_targets[0] == 0):\n",
    "            label_0s.append(0)\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data_set, target, columns)\n",
    "    column_median = numpy.median(data_set[best_column])\n",
    "    left_split = data_set[data_set[best_column] <= column_median]\n",
    "    right_split = data_set[data_set[best_column] > column_median]\n",
    "    \n",
    "    for split in [left_split, right_split]:\n",
    "        id3(split, target, columns)\n",
    "\n",
    "# Create a model dataset.\n",
    "data = pandas.DataFrame([\n",
    "    [0,20,0],\n",
    "    [0,60,2],\n",
    "    [0,40,1],\n",
    "    [1,25,1],\n",
    "    [1,35,2],\n",
    "    [1,55,1]\n",
    "    ])\n",
    "# Assign column names to the data.\n",
    "data.columns = [\"high_income\", \"age\", \"marital_status\"]\n",
    "\n",
    "# Call the function on our data to set the counters.\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"])\n",
    "print(label_1s, label_0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column': 'age', 'left': {'column': 'age', 'left': {'column': 'age', 'left': {'label': 0, 'number': 4}, 'number': 3, 'median': 22.5, 'right': {'label': 1, 'number': 5}}, 'number': 2, 'median': 25.0, 'right': {'label': 1, 'number': 6}}, 'number': 1, 'median': 37.5, 'right': {'column': 'age', 'left': {'column': 'age', 'left': {'label': 0, 'number': 9}, 'number': 8, 'median': 47.5, 'right': {'label': 1, 'number': 10}}, 'number': 7, 'median': 55.0, 'right': {'label': 0, 'number': 11}}}\n"
     ]
    }
   ],
   "source": [
    "# Now we'll use dictionaries to store the entire tree instead of just the labels at leaves.  \n",
    "tree = {}\n",
    "nodes = []\n",
    "\n",
    "def id3(data_set, target, columns, tree):\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree['number'] = nodes[-1]\n",
    "    \n",
    "    unique_targets = pandas.unique(data_set[target])\n",
    "    \n",
    "    if len(unique_targets) == 1:\n",
    "        if (unique_targets[0] == 1):\n",
    "            tree['label'] = 1\n",
    "        elif(unique_targets[0] == 0):\n",
    "            tree['label'] = 0\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data_set, target, columns)\n",
    "    column_median = numpy.median(data_set[best_column])\n",
    "    \n",
    "    tree['column'] = best_column\n",
    "    tree['median'] = column_median\n",
    "    \n",
    "    left_split = data_set[data_set[best_column] <= column_median]\n",
    "    right_split = data_set[data_set[best_column] > column_median]\n",
    "    \n",
    "    for name, split in [['left', left_split], ['right', right_split]]:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age > 37.5\n",
      "    age > 25.0\n",
      "        age > 22.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 1\n",
      "    age > 55.0\n",
      "        age > 47.5\n",
      "            Leaf: Label 0\n",
      "            Leaf: Label 1\n",
      "        Leaf: Label 0\n"
     ]
    }
   ],
   "source": [
    "# Print out dictionary in a nicer way\n",
    "def print_with_depth(string, depth):\n",
    "    # Add space before a string.\n",
    "    prefix = \"    \" * depth\n",
    "    # Print a string, appropriately indented.\n",
    "    print(\"{0}{1}\".format(prefix, string))\n",
    "    \n",
    "    \n",
    "def print_node(tree, depth):\n",
    "    # Check for the presence of label in the tree.\n",
    "    if \"label\" in tree:\n",
    "        # If there's a label, then this is a leaf, so print it and return.\n",
    "        print_with_depth(\"Leaf: Label {0}\".format(tree[\"label\"]), depth)\n",
    "        # This is critical -- without it, we'll get infinite recursion.\n",
    "        return\n",
    "    # Print information about what the node is splitting on.\n",
    "    print_with_depth(\"{0} > {1}\".format(tree[\"column\"], tree[\"median\"]), depth)\n",
    "    \n",
    "    # Create a list of tree branches.\n",
    "    branches = [tree[\"left\"], tree[\"right\"]]\n",
    "        \n",
    "    for branch in branches:\n",
    "        print_node(branch, depth+1)\n",
    "\n",
    "print_node(tree, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "def predict(tree, row):\n",
    "    if 'label' in tree:\n",
    "        return tree['label']\n",
    "    \n",
    "    column = tree['column']\n",
    "    median = tree['median']\n",
    "    \n",
    "    if row[column] <= median:\n",
    "        return predict(tree['left'], row)\n",
    "    else:\n",
    "        return predict(tree['right'], row)\n",
    "\n",
    "print(predict(tree, data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on multiple rows at once \n",
    "new_data = pandas.DataFrame([\n",
    "    [40,0],\n",
    "    [20,2],\n",
    "    [80,1],\n",
    "    [15,1],\n",
    "    [27,2],\n",
    "    [38,1]\n",
    "    ])\n",
    "# Assign column names to the data.\n",
    "new_data.columns = [\"age\", \"marital_status\"]\n",
    "\n",
    "predictions = new_data.apply(lambda row: predict(tree, row), axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the scikit-learn package to fit a decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \n",
    "           \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "# Set random_state to 1 to keep results consistent.\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(income[columns], income['high_income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the data by shuffling the order of the dataframe, then selecting certain rows to be in the training set, and certain rows to be in the testing set. Here we'll make 70% of our rows training data, and 30% testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "# Set a random seed so the shuffle is the same every time.\n",
    "numpy.random.seed(1)\n",
    "\n",
    "# Shuffle the rows.\n",
    "\n",
    "income = income.reindex(numpy.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .7)\n",
    "\n",
    "train = income.iloc[:train_max_row]\n",
    "test = income.iloc[train_max_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are many methods to evaluate error with classification, we'll use AUC here. AUC ranges from 0 to 1, and is ideal for binary classification. The higher the AUC, the more accurate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70548884174\n"
     ]
    }
   ],
   "source": [
    "# Evaluate error using AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "\n",
    "error = roc_auc_score(predictions, test['high_income'])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976351819595\n"
     ]
    }
   ],
   "source": [
    "# Compute error on the training set\n",
    "predictions = clf.predict(train[columns])\n",
    "error = roc_auc_score(predictions, train['high_income'])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC on the training set was 0.976. The AUC on the test set was 0.705. Our model is predicting the training set much better than it's predicting the test set. Based on our AUC measurements, it appears that we are in fact overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935645711968\n",
      "0.708880907772\n"
     ]
    }
   ],
   "source": [
    "# To reduce overfitting, adjust min_samples_split: the minimum number of rows needed in a node \n",
    "# before it can be split. \n",
    "# Set min_samples_split to 5\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=5)\n",
    "clf.fit(train[columns], train['high_income'])\n",
    "\n",
    "predictions_train = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(predictions_train, train['high_income'])\n",
    "\n",
    "predictions_test = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(predictions_test, test['high_income'])\n",
    "\n",
    "print(train_auc)\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By restricting min_samples_split to 5, we increased test AUC to 0.709 from 0.705. Training set AUC decreased from 0.976 to 0.936, showing that the model we built was less overfit to the training set than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79777759783\n",
      "0.792384918107\n"
     ]
    }
   ],
   "source": [
    "# More parameter tweaking: \n",
    "# Adjust max_depth, which restricts how deep the tree can go.\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=25, max_depth=4)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(predictions, test[\"high_income\"])\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train_predictions, train[\"high_income\"])\n",
    "\n",
    "print(test_auc)\n",
    "print(train_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both AUCs are about the same, we aren't overfitting anymore."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
